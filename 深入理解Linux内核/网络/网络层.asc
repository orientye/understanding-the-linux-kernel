:toc:
:toclevels: 5
:hardbreaks-option:

== 网络层

=== 结构
==== struct packet_type
网络层输入接口packet_type在链路层和网络层起到桥梁作用。
例如在以太网上，当以太网帧到达主机后，内核会根据协议族的报文类型调用相应的网络层接收处理函数。

[source, c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/netdevice.h
----
struct packet_type {
	__be16			type;	/* This is really htons(ether_type). */
	bool			ignore_outgoing;
	struct net_device	*dev;	/* NULL is wildcarded here	     */
	netdevice_tracker	dev_tracker;
	int			(*func) (struct sk_buff *,
					 struct net_device *,
					 struct packet_type *,
					 struct net_device *);
	void			(*list_func) (struct list_head *,
					      struct packet_type *,
					      struct net_device *);
	bool			(*id_match)(struct packet_type *ptype,
					    struct sock *sk);
	struct net		*af_packet_net;
	void			*af_packet_priv;
	struct list_head	list;
};
----

ipv4:
[source, c]
.https://elixir.bootlin.com/linux/latest/source/net/ipv4/af_inet.c
----
static struct packet_type ip_packet_type __read_mostly = {
	.type = cpu_to_be16(ETH_P_IP),
	.func = ip_rcv,
	.list_func = ip_list_rcv,
};
----

ipv6:
[source, c]
.https://elixir.bootlin.com/linux/latest/source/net/ipv6/af_inet6.c
----
static struct packet_type ipv6_packet_type __read_mostly = {
	.type = cpu_to_be16(ETH_P_IPV6),
	.func = ipv6_rcv,
	.list_func = ipv6_list_rcv,
};
----

=== 流量控制

==== 历史
2.2版本之前，不支持服务质量: 所有IP数据报采用FIFO，并尽最大努力传输，如果发生拥塞，路由器便会直接丢弃数据包。
随着网络的发展和数据量的增长，简单丢弃数据包的方式已经不再适用了，新的版本增加了QoS功能，目的是针对不同的需求，提供不同服务质量的网络服务功能。

==== 输出的流量控制
int __dev_queue_xmit(struct sk_buff *skb, struct net_device *sb_dev):
https://elixir.bootlin.com/linux/latest/source/net/core/dev.c

static inline bool qdisc_restart(struct Qdisc *q, int *packets):
https://elixir.bootlin.com/linux/latest/source/net/sched/sch_generic.c

==== 实现
- struct Qdisc

[source, c]
.https://elixir.bootlin.com/linux/latest/source/include/net/sch_generic.h
----
struct Qdisc {
	int 			(*enqueue)(struct sk_buff *skb,
					   struct Qdisc *sch,
					   struct sk_buff **to_free);
	struct sk_buff *	(*dequeue)(struct Qdisc *sch);
	unsigned int		flags;
#define TCQ_F_BUILTIN		1
#define TCQ_F_INGRESS		2
#define TCQ_F_CAN_BYPASS	4
#define TCQ_F_MQROOT		8
#define TCQ_F_ONETXQUEUE	0x10 /* dequeue_skb() can assume all skbs are for
				      * q->dev_queue : It can test
				      * netif_xmit_frozen_or_stopped() before
				      * dequeueing next packet.
				      * Its true for MQ/MQPRIO slaves, or non
				      * multiqueue device.
				      */
#define TCQ_F_WARN_NONWC	(1 << 16)
#define TCQ_F_CPUSTATS		0x20 /* run using percpu statistics */
#define TCQ_F_NOPARENT		0x40 /* root of its hierarchy :
				      * qdisc_tree_decrease_qlen() should stop.
				      */
#define TCQ_F_INVISIBLE		0x80 /* invisible by default in dump */
#define TCQ_F_NOLOCK		0x100 /* qdisc does not require locking */
#define TCQ_F_OFFLOADED		0x200 /* qdisc is offloaded to HW */
	u32			limit;
	const struct Qdisc_ops	*ops;
	struct qdisc_size_table	__rcu *stab;
	struct hlist_node       hash;
	u32			handle;
	u32			parent;

	struct netdev_queue	*dev_queue;

	struct net_rate_estimator __rcu *rate_est;
	struct gnet_stats_basic_sync __percpu *cpu_bstats;
	struct gnet_stats_queue	__percpu *cpu_qstats;
	int			pad;
	refcount_t		refcnt;

	/*
	 * For performance sake on SMP, we put highly modified fields at the end
	 */
	struct sk_buff_head	gso_skb ____cacheline_aligned_in_smp;
	struct qdisc_skb_head	q;
	struct gnet_stats_basic_sync bstats;
	struct gnet_stats_queue	qstats;
	unsigned long		state;
	unsigned long		state2; /* must be written under qdisc spinlock */
	struct Qdisc            *next_sched;
	struct sk_buff_head	skb_bad_txq;

	spinlock_t		busylock ____cacheline_aligned_in_smp;
	spinlock_t		seqlock;

	struct rcu_head		rcu;
	netdevice_tracker	dev_tracker;
	/* private data */
	long privdata[] ____cacheline_aligned;
};
----

- struct Qdisc_ops
https://elixir.bootlin.com/linux/latest/source/include/net/sch_generic.h

- struct tcf_proto
tcf: traffic control filter?
https://elixir.bootlin.com/linux/latest/source/include/net/sch_generic.h

==== FIFO
[source, c]
.https://elixir.bootlin.com/linux/latest/source/net/sched/sch_generic.c
----
struct Qdisc_ops pfifo_fast_ops __read_mostly = {
	.id		=	"pfifo_fast",
	.priv_size	=	sizeof(struct pfifo_fast_priv),
	.enqueue	=	pfifo_fast_enqueue,
	.dequeue	=	pfifo_fast_dequeue,
	.peek		=	pfifo_fast_peek,
	.init		=	pfifo_fast_init,
	.destroy	=	pfifo_fast_destroy,
	.reset		=	pfifo_fast_reset,
	.dump		=	pfifo_fast_dump,
	.change_tx_queue_len =  pfifo_fast_change_tx_queue_len,
	.owner		=	THIS_MODULE,
	.static_flags	=	TCQ_F_NOLOCK | TCQ_F_CPUSTATS,
};
----

==== 基于netlink的tc命令

=== 地址
struct in_device: https://elixir.bootlin.com/linux/latest/source/include/linux/inetdevice.h
struct in_ifaddr: https://elixir.bootlin.com/linux/latest/source/include/linux/inetdevice.h

static struct in_device *inetdev_init(struct net_device *dev):
static void inetdev_destroy(struct in_device *in_dev):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/devinet.c

int inet_addr_onlink(struct in_device *in_dev, __be32 a, __be32 b):
__be32 inet_select_addr(const struct net_device *dev, __be32 dst, int scope):
__be32 inet_confirm_addr(struct net *net, struct in_device *in_dev, __be32 dst, __be32 local, int scope)等:
https://elixir.bootlin.com/linux/latest/source/include/linux/inetdevice.h

=== 输入
int ip_rcv(struct sk_buff *skb, struct net_device *dev, struct packet_type *pt, struct net_device *orig_dev):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_input.c

int ipv6_rcv(struct sk_buff *skb, struct net_device *dev, struct packet_type *pt, struct net_device *orig_dev):
https://elixir.bootlin.com/linux/latest/source/net/ipv6/ip6_input.c

=== 输出
==== IP数据报输出到设备
int ip_output(struct net *net, struct sock *sk, struct sk_buff *skb):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_output.c

int ip6_output(struct net *net, struct sock *sk, struct sk_buff *skb):
https://elixir.bootlin.com/linux/latest/source/net/ipv6/ip6_output.c

==== TCP输出
int ip_queue_xmit(struct sock *sk, struct sk_buff *skb, struct flowi *fl):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_output.c

int ip6_xmit(const struct sock *sk, struct sk_buff *skb, struct flowi6 *fl6, __u32 mark, struct ipv6_txoptions *opt, int tclass, u32 priority):
https://elixir.bootlin.com/linux/latest/source/net/ipv6/ip6_output.c

==== UDP输出
[source, c]
.https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_output.c
----
/*
 *	ip_append_data() and ip_append_page() can make one large IP datagram
 *	from many pieces of data. Each pieces will be holded on the socket
 *	until ip_push_pending_frames() is called. Each piece can be a page
 *	or non-page data.
 *
 *	Not only UDP, other transport protocols - e.g. raw sockets - can use
 *	this interface potentially.
 *
 *	LATER: length must be adjusted by pad at tail, when it is required.
 */
----

==== 对GSO的支持
struct sk_buff *inet_gso_segment(struct sk_buff *skb, netdev_features_t features):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/af_inet.c

=== IP选项
概念:
IPv4允许最大选项长度40个字节，因此IPv4 header最大为60字节。

结构:
struct ip_options: https://elixir.bootlin.com/linux/latest/source/include/net/inet_sock.h

操作:
ip_options_build(), ip_options_fragment()等:
https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_options.c

参考:
https://en.wikipedia.org/wiki/Internet_Protocol_version_4#Header

=== IP的分片与组装
==== 分片(fragment)
如果IP数据报发送长度超过最大传输单元即MTU时，就需要对其进行分片。

[source, c]
.https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_output.c
----
static int ip_fragment(struct net *net, struct sock *sk, struct sk_buff *skb,
		       unsigned int mtu,
		       int (*output)(struct net *, struct sock *, struct sk_buff *))
----
核心函数:
int ip_do_fragment(struct net *net, struct sock *sk, struct sk_buff *skb, int (*output)(struct net *, struct sock *, struct sk_buff *))
快路径与慢路径:
不需要分片的IP packet或者已经按分片负载的长度分配好了buffer只要加个头的情况，属于快路径；
需要从头开始进行分配的IP packet，属于慢速路径。

==== 组装(重组)
在接收方，一个由发送方发出的IP数据报，其所有分片将被重新组合，然后提交给上层协议。

每个正在被重组的IP packet都会用一个ipq结构表示:
[source, c]
.https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_fragment.c
----
/* Describe an entry in the "incomplete datagrams" queue. */
struct ipq {
	struct inet_frag_queue q;

	u8		ecn; /* RFC3168 support */
	u16		max_df_size; /* largest frag with DF set seen */
	int             iif;
	unsigned int    rid;
	struct inet_peer *peer;
};
----

[source, c]
.https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_fragment.c
----
int ip_defrag(struct net *net, struct sk_buff *skb, u32 user)
----

==== 参考
https://ggaaooppeenngg.github.io/zh-CN/2017/07/10/IP-%E7%9A%84%E5%88%86%E7%89%87%E4%B8%8E%E9%87%8D%E7%BB%84/

=== IP组播
- IP报文网络传输的三种模式
    
    单播是主机间一对一的通讯模式
    
    广播是主机间一对所有的通讯模式
    广播方式下，发送者与用户主机被限制在一个共享网段中，且该网段所有用户主机都能接收到该信息，可能导致冗余和不安全。

    组播是主机间一对多的通讯模式
    组播可以跨网段传输，不需要此报文的用户不能收到此报文
    相比广播来说，使用组播方式可以远距离传输信息，并且只会将信息传输到相应的接收者，保障了信息的安全性。

初始化:
int __init ip_mr_init(void):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/ipmr.c

虚拟接口:
struct vif_device:
https://elixir.bootlin.com/linux/latest/source/include/linux/mroute_base.h

组播转发缓存:
struct mfc_cache:
https://elixir.bootlin.com/linux/latest/source/include/linux/mroute.h

struct mr_table:
https://elixir.bootlin.com/linux/latest/source/include/linux/mroute_base.h

组播报文的输入:
int ip_mr_input(struct sk_buff *skb):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/ipmr.c

组播报文的转发:
void ip_mr_forward(struct net *net, struct mr_table *mrt, struct net_device *dev, struct sk_buff *skb, struct mfc_cache *c, int local):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/ipmr.c

组播报文的输出:
int ip_mc_output(struct net *net, struct sock *sk, struct sk_buff *skb):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/ip_output.c

=== 路由

=== ICMP
ICMP是什么？
因特网控制报文协议ICMP(Internet Control Message Protocol)
ICMP是一个差错报告机制，主要用于在IP主机和路由器之间传递控制消息，用于报告主机是否可达、路由是否可用等。它虽然并不传输用户数据，但是对于收集各种网络信息、诊断和排除各种网络故障以及用户数据的传递作用重大。

为什么需要ICMP？
在数据传输的过程中，IP提供尽力而为的服务，指为了把数据包发送到目的地址尽最大努力。它并不对目的主机是否收到数据包进行验证，无法进行流量控制和差错控制。因此在数据包传输过程中，产生各种错误在所难免。为了更有效地转发IP数据包和提高数据包交付成功的机会，ICMP应运而生。使用ICMP，当网络中数据包传输出现问题时，主机或设备就会向上层协议报告差错情况和提供有关异常情况的报告，使得上层协议能够通过自己的差错控制程序来判断通信是否正确，以进行流量控制和差错控制，从而保证服务质量。

典型应用:
ping程序和tracer/traceroute程序，网络质量分析NQA(Network Quality Analysis)等。

协议:
[source, c]
.https://elixir.bootlin.com/linux/latest/source/net/ipv4/af_inet.c
----
static const struct net_protocol icmp_protocol = {
	.handler =	icmp_rcv,
	.err_handler =	icmp_err,
	.no_policy =	1,
};
----

初始化:
int __init icmp_init(void):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/icmp.c

输入:
int icmp_rcv(struct sk_buff *skb):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/icmp.c

输出:
void __icmp_send(struct sk_buff *skb_in, int type, int code, __be32 info, const struct ip_options *opt):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/icmp.c

=== IGMP
IGMP(Internet Group Management Protocol)
IMGP是互联网组管理协议是TCP/IP协议族中负责IP组播成员管理的协议，用来在IP主机和与其直接相邻的组播路由器之间建立、维护组播组成员关系。

IGMP报文的输入:
int igmp_rcv(struct sk_buff *skb):
https://elixir.bootlin.com/linux/latest/source/net/ipv4/igmp.c

=== 邻居子系统
struct neigh_table:
https://elixir.bootlin.com/linux/latest/source/include/net/neighbour.h

struct neighbour:
https://elixir.bootlin.com/linux/latest/source/include/net/neighbour.h

=== ARP
https://elixir.bootlin.com/linux/latest/source/net/ipv4/arp.c

=== NDP
邻居发现协议NDP(Neighbor Discovery Protocol)是IPv6协议体系中一个重要的基础协议。
邻居发现协议替代了IPv4的ARP(Address Resolution Protocol)和ICMP路由器发现(Router Discovery)，它定义了使用ICMPv6报文实现地址解析，跟踪邻居状态，重复地址检测，路由器发现以及重定向等功能。