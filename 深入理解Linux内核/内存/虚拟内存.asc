:toc:
:toclevels: 5
:hardbreaks-option:

== 虚拟内存

=== 作用
- Caching

    It uses mainmemory efficiently by treating it as a cache for an address space stored on disk, 
    keeping only the active areas in main memory and transferring data back and forth between disk and memory as needed. 

- Memory Management

    It simplifies memory management by providing each process with a uniform address space.
    简化: 链接, 加载, 共享, 内存分配

- Memory Protection

    It protects the address space of each process from corruption by other processes.
	如果一条指令违反权限，会触发异常，发送一个SIGSEGV signal，linux称之为segmentation fault

=== 空间划分
==== 概念
虚拟空间划分为用户空间与内核空间:
不同的用户进程，虚拟空间不同
内核空间则是一样的，所有进程共享一个内核空间
以TASK_SIZE大小划分用户空间与内核空间

==== 32位虚拟空间划分
32位下的用户空间
32位下: 0xC0000000 即3G
https://elixir.bootlin.com/linux/latest/source/arch/x86/include/asm/page_32_types.h

32位下的内核空间
1. 3G - 3G+896M
直接进行映射的896MB物理内存其实又分为两个区域, 在低于16MB的区域, ISA设备可以做DMA, 所以该区域为DMA区域(内核为了保证ISA驱动在申请DMA缓冲区的时候, 通过GFP_DMA标记可以确保申请到16MB以内的内存, 所以必须把这个区域列为一个单独的区域管理); 16MB~896MB之间的为常规区域。 
2. 3G+896M - 4G(即high memory)
这一部分又可以划分为三部分: vmalloc区，固定映射区，临时映射区。

https://www.kernel.org/doc/html/latest/mm/highmem.html
https://linux-kernel-labs.github.io/refs/heads/master/lectures/address-space.html
ARM: https://www.arm.linux.org.uk/developer/memory.txt

==== 64位虚拟空间划分
64位下用户空间: 1<<47, 即128T(4级页表下)
[source,c]
.https://elixir.bootlin.com/linux/latest/source/arch/x86/include/asm/page_64_types.h
----
#ifdef CONFIG_X86_5LEVEL
#define __VIRTUAL_MASK_SHIFT	(pgtable_l5_enabled() ? 56 : 47)
/* See task_size_max() in <asm/page_64.h> */
#else
#define __VIRTUAL_MASK_SHIFT	47
#define task_size_max()		((_AC(1,UL) << __VIRTUAL_MASK_SHIFT) - PAGE_SIZE)
#endif
----

随机性: CONFIG_DYNAMIC_MEMORY_LAYOUT

参考: https://github.com/torvalds/linux/blob/master/Documentation/x86/x86_64/mm.rst

==== 虚拟空间与多进程多线程
对于用户进程，主线程堆栈也称进程栈；非主线程堆栈也叫线程栈。
对于同一个用户进程下的多线程，共享进程的虚拟空间，主线程的堆栈就是进程的堆栈，非主线程的堆栈又是如何分配的呢？
一般是从heap的顶部附近向下分配8M大小，多个(非主)线程之间会有少量间隔填充。

=== 用户空间

==== 数据结构
每个用户进程拥有一个struct mm_struct
一个用户进程下的多线程，共享进程的虚拟空间

==== 布局
布局:
当前运行代码的二进制代码
程序使用的动态库代码
存储全局变量和动态产生的数据的堆
保存局部变量和实现函数/过程调用的栈
环境变量和命令行参数
将文件内容映射到虚拟地址空间中的内存映射

布局的建立:
load_elf_binary()(execve系统调用使用了此函数): https://elixir.bootlin.com/linux/latest/source/fs/binfmt_elf.c

Q: 环境变量和命令行参数存在哪里？
https://unix.stackexchange.com/questions/75939/where-is-the-environment-string-actual-stored

==== 空间切换[[空间切换]]
[source,c]
.https://elixir.bootlin.com/linux/latest/source/arch/x86/mm/tlb.c
----
void switch_mm(struct mm_struct *prev, struct mm_struct *next,
	       struct task_struct *tsk)
{
	unsigned long flags;

	local_irq_save(flags);
	switch_mm_irqs_off(prev, next, tsk);//切换地址空间
	local_irq_restore(flags);
}

void switch_mm_irqs_off(struct mm_struct *prev, struct mm_struct *next,
			struct task_struct *tsk)
{
	struct mm_struct *real_prev = this_cpu_read(cpu_tlbstate.loaded_mm);
	u16 prev_asid = this_cpu_read(cpu_tlbstate.loaded_mm_asid);
	bool was_lazy = this_cpu_read(cpu_tlbstate_shared.is_lazy);
	unsigned cpu = smp_processor_id();
	u64 next_tlb_gen;
	bool need_flush;
	u16 new_asid;

	/*
	 * NB: The scheduler will call us with prev == next when switching
	 * from lazy TLB mode to normal mode if active_mm isn't changing.
	 * When this happens, we don't assume that CR3 (and hence
	 * cpu_tlbstate.loaded_mm) matches next.
	 *
	 * NB: leave_mm() calls us with prev == NULL and tsk == NULL.
	 */

	/* We don't want flush_tlb_func() to run concurrently with us. */
	if (IS_ENABLED(CONFIG_PROVE_LOCKING))
		WARN_ON_ONCE(!irqs_disabled());

	/*
	 * Verify that CR3 is what we think it is.  This will catch
	 * hypothetical buggy code that directly switches to swapper_pg_dir
	 * without going through leave_mm() / switch_mm_irqs_off() or that
	 * does something like write_cr3(read_cr3_pa()).
	 *
	 * Only do this check if CONFIG_DEBUG_VM=y because __read_cr3()
	 * isn't free.
	 */
#ifdef CONFIG_DEBUG_VM
	if (WARN_ON_ONCE(__read_cr3() != build_cr3(real_prev->pgd, prev_asid))) {
		/*
		 * If we were to BUG here, we'd be very likely to kill
		 * the system so hard that we don't see the call trace.
		 * Try to recover instead by ignoring the error and doing
		 * a global flush to minimize the chance of corruption.
		 *
		 * (This is far from being a fully correct recovery.
		 *  Architecturally, the CPU could prefetch something
		 *  back into an incorrect ASID slot and leave it there
		 *  to cause trouble down the road.  It's better than
		 *  nothing, though.)
		 */
		__flush_tlb_all();
	}
#endif
	if (was_lazy)
		this_cpu_write(cpu_tlbstate_shared.is_lazy, false);

	/*
	 * The membarrier system call requires a full memory barrier and
	 * core serialization before returning to user-space, after
	 * storing to rq->curr, when changing mm.  This is because
	 * membarrier() sends IPIs to all CPUs that are in the target mm
	 * to make them issue memory barriers.  However, if another CPU
	 * switches to/from the target mm concurrently with
	 * membarrier(), it can cause that CPU not to receive an IPI
	 * when it really should issue a memory barrier.  Writing to CR3
	 * provides that full memory barrier and core serializing
	 * instruction.
	 */
	if (real_prev == next) {
		VM_WARN_ON(this_cpu_read(cpu_tlbstate.ctxs[prev_asid].ctx_id) !=
			   next->context.ctx_id);

		/*
		 * Even in lazy TLB mode, the CPU should stay set in the
		 * mm_cpumask. The TLB shootdown code can figure out from
		 * cpu_tlbstate_shared.is_lazy whether or not to send an IPI.
		 */
		if (WARN_ON_ONCE(real_prev != &init_mm &&
				 !cpumask_test_cpu(cpu, mm_cpumask(next))))
			cpumask_set_cpu(cpu, mm_cpumask(next));

		/*
		 * If the CPU is not in lazy TLB mode, we are just switching
		 * from one thread in a process to another thread in the same
		 * process. No TLB flush required.
		 */
		if (!was_lazy)
			return;

		/*
		 * Read the tlb_gen to check whether a flush is needed.
		 * If the TLB is up to date, just use it.
		 * The barrier synchronizes with the tlb_gen increment in
		 * the TLB shootdown code.
		 */
		smp_mb();
		next_tlb_gen = atomic64_read(&next->context.tlb_gen);
		if (this_cpu_read(cpu_tlbstate.ctxs[prev_asid].tlb_gen) ==
				next_tlb_gen)
			return;

		/*
		 * TLB contents went out of date while we were in lazy
		 * mode. Fall through to the TLB switching code below.
		 */
		new_asid = prev_asid;
		need_flush = true;
	} else {
		/*
		 * Apply process to process speculation vulnerability
		 * mitigations if applicable.
		 */
		cond_mitigation(tsk);

		/*
		 * Stop remote flushes for the previous mm.
		 * Skip kernel threads; we never send init_mm TLB flushing IPIs,
		 * but the bitmap manipulation can cause cache line contention.
		 */
		if (real_prev != &init_mm) {
			VM_WARN_ON_ONCE(!cpumask_test_cpu(cpu,
						mm_cpumask(real_prev)));
			cpumask_clear_cpu(cpu, mm_cpumask(real_prev));
		}

		/*
		 * Start remote flushes and then read tlb_gen.
		 */
		if (next != &init_mm)
			cpumask_set_cpu(cpu, mm_cpumask(next));
		next_tlb_gen = atomic64_read(&next->context.tlb_gen);

		choose_new_asid(next, next_tlb_gen, &new_asid, &need_flush);

		/* Let nmi_uaccess_okay() know that we're changing CR3. */
		this_cpu_write(cpu_tlbstate.loaded_mm, LOADED_MM_SWITCHING);
		barrier();
	}

	if (need_flush) {
		this_cpu_write(cpu_tlbstate.ctxs[new_asid].ctx_id, next->context.ctx_id);
		this_cpu_write(cpu_tlbstate.ctxs[new_asid].tlb_gen, next_tlb_gen);
		load_new_mm_cr3(next->pgd, new_asid, true);

		trace_tlb_flush(TLB_FLUSH_ON_TASK_SWITCH, TLB_FLUSH_ALL);
	} else {
		/* The new ASID is already up to date. */
		load_new_mm_cr3(next->pgd, new_asid, false);

		trace_tlb_flush(TLB_FLUSH_ON_TASK_SWITCH, 0);
	}

	/* Make sure we write CR3 before loaded_mm. */
	barrier();

	this_cpu_write(cpu_tlbstate.loaded_mm, next);
	this_cpu_write(cpu_tlbstate.loaded_mm_asid, new_asid);

	if (next != real_prev) {
		cr4_update_pce_mm(next);
		switch_ldt(real_prev, next);
	}
}
----

参考: http://www.wowotech.net/process_management/context-switch-arch.html

=== 内核空间

==== 布局
https://github.com/torvalds/linux/blob/master/Documentation/x86/x86_64/mm.rst

========================================================================================================================
    Start addr    |   Offset   |     End addr     |  Size   | VM area description
========================================================================================================================
                  |            |                  |         |
 0000000000000000 |    0       | 00007fffffffffff |  128 TB | user-space virtual memory, different per mm
__________________|____________|__________________|_________|___________________________________________________________
                  |            |                  |         |
 0000800000000000 | +128    TB | ffff7fffffffffff | ~16M TB | ... huge, almost 64 bits wide hole of non-canonical
                  |            |                  |         |     virtual memory addresses up to the -128 TB
                  |            |                  |         |     starting offset of kernel mappings.
__________________|____________|__________________|_________|___________________________________________________________
                                                            |
                                                            | Kernel-space virtual memory, shared between all processes:
____________________________________________________________|___________________________________________________________
                  |            |                  |         |
 ffff800000000000 | -128    TB | ffff87ffffffffff |    8 TB | ... guard hole, also reserved for hypervisor
 ffff880000000000 | -120    TB | ffff887fffffffff |  0.5 TB | LDT remap for PTI
 ffff888000000000 | -119.5  TB | ffffc87fffffffff |   64 TB | direct mapping of all physical memory (page_offset_base)
 ffffc88000000000 |  -55.5  TB | ffffc8ffffffffff |  0.5 TB | ... unused hole
 ffffc90000000000 |  -55    TB | ffffe8ffffffffff |   32 TB | vmalloc/ioremap space (vmalloc_base)
 ffffe90000000000 |  -23    TB | ffffe9ffffffffff |    1 TB | ... unused hole
 ffffea0000000000 |  -22    TB | ffffeaffffffffff |    1 TB | virtual memory map (vmemmap_base)
 ffffeb0000000000 |  -21    TB | ffffebffffffffff |    1 TB | ... unused hole
 ffffec0000000000 |  -20    TB | fffffbffffffffff |   16 TB | KASAN shadow memory
__________________|____________|__________________|_________|____________________________________________________________
                                                            |
                                                            | Identical layout to the 56-bit one from here on:
____________________________________________________________|____________________________________________________________
                  |            |                  |         |
 fffffc0000000000 |   -4    TB | fffffdffffffffff |    2 TB | ... unused hole
                  |            |                  |         | vaddr_end for KASLR
 fffffe0000000000 |   -2    TB | fffffe7fffffffff |  0.5 TB | cpu_entry_area mapping
 fffffe8000000000 |   -1.5  TB | fffffeffffffffff |  0.5 TB | ... unused hole
 ffffff0000000000 |   -1    TB | ffffff7fffffffff |  0.5 TB | %esp fixup stacks
 ffffff8000000000 | -512    GB | ffffffeeffffffff |  444 GB | ... unused hole
 ffffffef00000000 |  -68    GB | fffffffeffffffff |   64 GB | EFI region mapping space
 ffffffff00000000 |   -4    GB | ffffffff7fffffff |    2 GB | ... unused hole
 ffffffff80000000 |   -2    GB | ffffffff9fffffff |  512 MB | kernel text mapping, mapped to physical address 0
 ffffffff80000000 |-2048    MB |                  |         |
 ffffffffa0000000 |-1536    MB | fffffffffeffffff | 1520 MB | module mapping space
 ffffffffff000000 |  -16    MB |                  |         |
    FIXADDR_START | ~-11    MB | ffffffffff5fffff | ~0.5 MB | kernel-internal fixmap range, variable size and offset
 ffffffffff600000 |  -10    MB | ffffffffff600fff |    4 kB | legacy vsyscall ABI
 ffffffffffe00000 |   -2    MB | ffffffffffffffff |    2 MB | ... unused hole
__________________|____________|__________________|_________|___________________________________________________________

==== 空间切换
对于arm64架构来说，有两个页表基址寄存器ttbr0_el1和ttbr1_el1, ttbr0_el1用来存放用户地址空间的页表基地址，在每次调度上下文切换的时候从tsk->mm->pgd加载，ttbr1_el1是内核地址空间的页表基地址，内核初始化完成之后存放swapper_pg_dir的地址。
内核线程共享内核地址空间，也只能访问内核地址空间，使用swapper_pg_dir去查询页表就可以，而对于arm64来说swapper_pg_dir在内核初始化的时候被加载到ttbr1_le1中，一旦内核线程访问内核虚拟地址，则mmu就会从ttbr1_le1指向的页表基地址开始查询各级页表，进行正常的虚实地址转换。当然，上面是arm64这种架构的处理，它有两个页表基地址寄存器，其他很多处理器如x86, riscv处理器架构都只有一个页表基址寄存器，如x86的cr3，那么这个时候怎么办呢？答案是：使用内核线程借用的prev->active_mm来做，实际上前一个用户任务（记住：不一定是上一个，有可能上上个任务才是用户任务）的active_mm=mm,当切换到前一个用户任务的时候就会将tsk->mm->pgd放到cr3, 对于x86这样的只有一个页表基址寄存器的处理器架构来说，tsk->mm->pgd存放的是整个虚拟地址空间的页表基地址，在fork的时候会将主内核页表的pgd表项拷贝到tsk->mm->pgd对于表项中（有兴趣可以查看fork的copy_mm相关代码，对于arm64这样的架构没有做内核页表同步）。
参考: https://zhuanlan.zhihu.com/p/373959024
参考: https://mp.weixin.qq.com/s/pmWuGS6thCj6GNwwjh0bRw

=== 内存映射
==== 作用与原理
Linux initializes the contents of a virtual memory area by associating it with an object on disk, a process known as memory mapping. 

Areas can be mapped to one of two types of objects:

1. Regular file in the Linux file system: An area can be mapped to a contiguous section of a regular disk file, such as an executable object file. The file section is divided into page-size pieces, with each piece containing the initial contents of a virtual page. Because of demand paging, none of these virtual pages is actually swapped into physical memory until the CPU first touches the page (i.e., issues a virtual address that falls within that page’s region of the address space). If the area is larger than the file section, then the area is padded with zeros. 适合于很大的文件

2. Anonymous file: An area can also be mapped to an anonymous file, created by the kernel, that contains all binary zeros. The first time the CPU touches a virtual page in such an area, the kernel finds an appropriate victim page in physical memory, swaps out the victim page if it is dirty, overwrites the victim page with binary zeros, and updates the page table to mark the page as resident. Notice that no data are actually transferred between disk and memory. For this reason, pages in areas that are mapped to anonymous files are sometimes called demand-zero pages. 适合于创建进程间通信的共享内存。

In either case, once a virtual page is initialized, it is swapped back and forthbetween a special swap file maintained by the kernel. The swap file is also known as the swap space or the swap area. An important point to realize is that at any point in time, the swap space bounds the total amount of virtual pages that can be allocated by the currently running processes.

内存映射是一种重要的抽象，在内核和应用程序中均大量使用。内存映射将数据映射到进程的虚拟地址空间中。作为映射目标的地址空间区域，对改区域的内存修改都会自动同步到数据源。例如，文件的内容映射到内存中，处理只需要读取相应的内存即可访问文件内容，或向内存写入数据来修改文件的内容，内核保证任何修改都会自动同步到文件中。内核在实现设备驱动程序时直接使用了内存映射，外设的输入/输出可以映射到虚拟地址空间的区域中，对相关内存区域的都写会由系统重定向到设备，因而大大简化了驱动程序的实现。

▪ 问题
内存映射文件需要在进程上占用一块很大的连续地址空间。对于Intel的IA-32的4G逻辑地址空间，可用的连续地址空间远远小于2-3G。
相关联的文件的I/O错误(如可拔出驱动器或光驱被弹出，磁盘满时写操作等)的内存映射文件会向应用程序报告SIGSEGV/SIGBUS信号(POSIX环境)或EXECUTE_IN_PAGE_ERROR结构化异常(Windows环境)。通常的内存操作是无需考虑这些异常的。
有内存管理单元(MMU)才支持内存映射文件。

参考: CSAPP 3rd, 9.8
参考: https://linux-kernel-labs.github.io/refs/heads/master/labs/memory_mapping.html

==== 用户空间映射
▪ 私有/共享、文件/匿名
匿名映射：没有映射对应的相关文件，其映射的内存区域的内容会被初始化为0。
文件映射：映射和实际文件相关联，通常是把文件的内容映射到进程地址空间，应用程序可以像操作进程地址空间一样读写文件。
(1)私有文件映射: 多个进程使用同样的物理页面进行初始化，但是各个进程对内存文件的修改不会共享，也不会反映到物理文件中。例如.so动态库文件就采用这种方式映射到各个进程虚拟地址空间中。
(2)共享文件映射: 多个进程通过虚拟内存技术共享同样物理内存，对内存文件的修改会反应到实际物理内存中，也是进程间通信的一种。
(3)私有匿名映射: mmap会创建一个新的映射，各个进程不共享，主要用于malloc分配大(>MMAP THRESHOLD)内存。
(4)共享匿名映射: 共享匿名映射让相关进程共享一块内存区域，通常用于父子进程的之间通信。

参考: https://man7.org/linux/man-pages/man2/mmap.2.html

==== 内核空间映射[[内核空间映射]]
===== 持久内核映射
kmap(): https://elixir.bootlin.com/linux/latest/source/include/linux/highmem-internal.h
kmap函数不能用于中断处理程序, 因为它可能进入睡眠状态

===== 固定内存映射/临时内核映射
kmap_atomic(): https://elixir.bootlin.com/linux/latest/source/include/linux/highmem-internal.h
kmap_atomic函数不能用于可能进入睡眠的代码

===== 没有高端内存的计算机上的映射函数
许多体系结构不支持高端内存, 例如64位体系结构: 内核提供了兼容宏CONFIG_HIGHMEM

===== 外部设备存储空间的地址映射
一般来说，对外部设备的访问有两种不同的形式，一种叫做内存映射式(memory mapped), 另一种叫做IO映射式(I/O mapped)。

对于内存映射式，外部设备的存储单元例如控制寄存器，状态寄存器，数据寄存器等，是作为内存的一部分出现在系统中的。CPU可以像访问一个内存单元一样访问外部设备的内存单元，因此不需要专门用于外设I/O的指令。

对于IO映射式，外部设备的存储单元与内存属于两个不同的体系，访问内存的指令不能用于访问外部设备的存储单元，例如X86的IN和OUT指令， 但通常用于IO指令的地址空间相对来说是很小的。可以说，IO映射式只适合与早期的计算机技术，彼时外设通常只有几个寄存器，通过这几个寄存器就能完成对外设的所有操作。随着计算机技术的发展，单纯的IO映射方式显然已经不能满足需求了。

尤其随着显卡以及PCI总线的出现，不管是采用IO映射还是内存映射，都需要将外设上的存储器映射到内存空间。在linux内核中，通过函数ioremap()来建立这个映射。

https://elixir.bootlin.com/linux/latest/source/arch/x86/mm/ioremap.c

    ioremap()
    iounmap()

===== 反向映射/逆向映射
给定物理页面，查找其对应的所有进程的VMA对应的页表项，即如何确定该物理内存有哪些进程正在使用/通过物理页查找虚拟页。

建立逆向映射机制主要是为了方便页面回收。

参考: https://blog.csdn.net/u010923083/article/details/116456497
参考: https://lwn.net/Articles/23732/
参考: http://www.wowotech.net/memory_management/reverse_mapping.html

=== v0.12
v0.12默认最多支持64M逻辑地址空间

=== 参考
https://lwn.net/Articles/253361/
https://people.freebsd.org/~lstewart/articles/cpumemory.pdf