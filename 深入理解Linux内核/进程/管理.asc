:toc:
:toclevels: 5
:hardbreaks-option:

== 管理

=== 创建/复制
- now
https://elixir.bootlin.com/linux/latest/source/kernel/fork.c

    struct task_struct * __init fork_idle(int cpu) //smpboot
    struct task_struct *create_io_thread(int (*fn)(void *), void *arg, int node)//for io_uring
    pid_t kernel_clone(struct kernel_clone_args *args)//main
        三个函数最终都会调用: copy_process(struct pid *pid, int trace, int node, struct kernel_clone_args *args)

- old

    fork copy-on-write(COW)
    vfork 效率较慢, 避免使用
    clone 产生线程

    三个函数最后都会调用do_fork, 参数不同而已
    fork/vfork/clone
        sys_fork/sys_vfork/sys_clone
            kernel/fork.c
                do_fork
                    copy_process

由此也可见，copy_process是创建/复制的核心函数。

==== copy_process

===== clone flags

[source,c]
.https://elixir.bootlin.com/linux/latest/source/include/uapi/linux/sched.h
----
/*
 * cloning flags:
 */
#define CSIGNAL		0x000000ff	/* signal mask to be sent at exit */
#define CLONE_VM	0x00000100	/* set if VM shared between processes */
#define CLONE_FS	0x00000200	/* set if fs info shared between processes */
#define CLONE_FILES	0x00000400	/* set if open files shared between processes */
#define CLONE_SIGHAND	0x00000800	/* set if signal handlers and blocked signals shared */
#define CLONE_PIDFD	0x00001000	/* set if a pidfd should be placed in parent */
#define CLONE_PTRACE	0x00002000	/* set if we want to let tracing continue on the child too */
#define CLONE_VFORK	0x00004000	/* set if the parent wants the child to wake it up on mm_release */
#define CLONE_PARENT	0x00008000	/* set if we want to have the same parent as the cloner */
#define CLONE_THREAD	0x00010000	/* Same thread group? */
#define CLONE_NEWNS	0x00020000	/* New mount namespace group */
#define CLONE_SYSVSEM	0x00040000	/* share system V SEM_UNDO semantics */
#define CLONE_SETTLS	0x00080000	/* create a new TLS for the child */
#define CLONE_PARENT_SETTID	0x00100000	/* set the TID in the parent */
#define CLONE_CHILD_CLEARTID	0x00200000	/* clear the TID in the child */
#define CLONE_DETACHED		0x00400000	/* Unused, ignored */
#define CLONE_UNTRACED		0x00800000	/* set if the tracing process can't force CLONE_PTRACE on this clone */
#define CLONE_CHILD_SETTID	0x01000000	/* set the TID in the child */
#define CLONE_NEWCGROUP		0x02000000	/* New cgroup namespace */
#define CLONE_NEWUTS		0x04000000	/* New utsname namespace */
#define CLONE_NEWIPC		0x08000000	/* New ipc namespace */
#define CLONE_NEWUSER		0x10000000	/* New user namespace */
#define CLONE_NEWPID		0x20000000	/* New pid namespace */
#define CLONE_NEWNET		0x40000000	/* New network namespace */
#define CLONE_IO		0x80000000	/* Clone io context */

/* Flags for the clone3() syscall. */
#define CLONE_CLEAR_SIGHAND 0x100000000ULL /* Clear any signal handler and reset to SIG_DFL. */
#define CLONE_INTO_CGROUP 0x200000000ULL /* Clone into a specific cgroup given the right permissions. */

/*
 * cloning flags intersect with CSIGNAL so can be used with unshare and clone3
 * syscalls only:
 */
#define CLONE_NEWTIME	0x00000080	/* New time namespace */
----

===== clone args

[source,c]
.https://elixir.bootlin.com/linux/latest/source/include/uapi/linux/sched.h
----
#ifndef __ASSEMBLY__
/**
 * struct clone_args - arguments for the clone3 syscall
 * @flags:        Flags for the new process as listed above.
 *                All flags are valid except for CSIGNAL and
 *                CLONE_DETACHED.
 * @pidfd:        If CLONE_PIDFD is set, a pidfd will be
 *                returned in this argument.
 * @child_tid:    If CLONE_CHILD_SETTID is set, the TID of the
 *                child process will be returned in the child's
 *                memory.
 * @parent_tid:   If CLONE_PARENT_SETTID is set, the TID of
 *                the child process will be returned in the
 *                parent's memory.
 * @exit_signal:  The exit_signal the parent process will be
 *                sent when the child exits.
 * @stack:        Specify the location of the stack for the
 *                child process.
 *                Note, @stack is expected to point to the
 *                lowest address. The stack direction will be
 *                determined by the kernel and set up
 *                appropriately based on @stack_size.
 * @stack_size:   The size of the stack for the child process.
 * @tls:          If CLONE_SETTLS is set, the tls descriptor
 *                is set to tls.
 * @set_tid:      Pointer to an array of type *pid_t. The size
 *                of the array is defined using @set_tid_size.
 *                This array is used to select PIDs/TIDs for
 *                newly created processes. The first element in
 *                this defines the PID in the most nested PID
 *                namespace. Each additional element in the array
 *                defines the PID in the parent PID namespace of
 *                the original PID namespace. If the array has
 *                less entries than the number of currently
 *                nested PID namespaces only the PIDs in the
 *                corresponding namespaces are set.
 * @set_tid_size: This defines the size of the array referenced
 *                in @set_tid. This cannot be larger than the
 *                kernel's limit of nested PID namespaces.
 * @cgroup:       If CLONE_INTO_CGROUP is specified set this to
 *                a file descriptor for the cgroup.
 *
 * The structure is versioned by size and thus extensible.
 * New struct members must go at the end of the struct and
 * must be properly 64bit aligned.
 */
struct clone_args {
	__aligned_u64 flags;
	__aligned_u64 pidfd;
	__aligned_u64 child_tid;
	__aligned_u64 parent_tid;
	__aligned_u64 exit_signal;
	__aligned_u64 stack;
	__aligned_u64 stack_size;
	__aligned_u64 tls;
	__aligned_u64 set_tid;
	__aligned_u64 set_tid_size;
	__aligned_u64 cgroup;
};
#endif
----

[source,c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/sched/task.h
----
struct kernel_clone_args {
	u64 flags;
	int __user *pidfd;
	int __user *child_tid;
	int __user *parent_tid;
	int exit_signal;
	unsigned long stack;
	unsigned long stack_size;
	unsigned long tls;
	pid_t *set_tid;
	/* Number of elements in *set_tid */
	size_t set_tid_size;
	int cgroup;
	int io_thread;
	int kthread;
	int idle;
	int (*fn)(void *);
	void *fn_arg;
	struct cgroup *cgrp;
	struct css_set *cset;
};
----

===== 主流程
copy_process(struct pid *pid, int trace, int node, struct kernel_clone_args *args)
[source,c]
.https://elixir.bootlin.com/linux/latest/source/kernel/fork.c
----
/*
 * This creates a new process as a copy of the old one,
 * but does not actually start it yet.
 *
 * It copies the registers, and all the appropriate
 * parts of the process environment (as per the clone
 * flags). The actual kick-off is left to the caller.
 */
static __latent_entropy struct task_struct *copy_process(
					struct pid *pid,
					int trace,
					int node,
					struct kernel_clone_args *args)
{
	int pidfd = -1, retval;
	struct task_struct *p;
	struct multiprocess_signals delayed;
	struct file *pidfile = NULL;
	const u64 clone_flags = args->flags;
	struct nsproxy *nsp = current->nsproxy;

	//clone_flags检查

	//信号处理相关

	//dup_task_struct
	p = dup_task_struct(current, node);

	//task_struct一些变量赋值
	p->flags 
	p->blocked
	p->set_child_tid
	p->clear_child_tid

	//init task_struct
	ftrace_graph_init_task(p);
	rt_mutex_init_task(p);

	copy_creds(p, clone_flags);

	delayacct_tsk_init(p);
	p->flags
	p->children
	p->sibling
	rcu_copy_process(p);
	p->vfork_done
	spin_lock_init(&p->alloc_lock);

	init_sigpending(&p->pending);

	p->utime p->stime p->gtime
	p->utimescaled p->stimescaled
	p->prev_cputime
	p->vtime.seqcount
	p->vtime.starttime
	p->vtime.state

	p->io_uring
	
	p->rss_stat
	p->default_timer_slack_ns

	p->psi_flags

	task_io_accounting_init(&p->ioac);
	acct_clear_integrals(p);

	posix_cputimers_init(&p->posix_cputimers);

	p->io_context;
	audit_set_context(p, NULL);
	cgroup_fork(p);
	set_kthread_struct(p))
	
	p->mempolicy

	p->cpuset_mem_spread_rotor
	p->cpuset_slab_spread_rotor
	p->mems_allowed_seq, p->alloc_lock

	p->irqtrace.hardirq_disable_ip
	p->irqtrace.softirq_enable_ip
	p->softirqs_enabled
	p->softirq_context

	p->pagefault_disabled

	lockdep_init_task(p);

	p->blocked_on
	p->sequential_io
	p->sequential_io_avg
	p->bpf_storage
	p->bpf_ctx

	/* Perform scheduler related setup. Assign this task to a CPU. */
	sched_fork(clone_flags, p);

	perf_event_init_task(p, clone_flags);
	audit_alloc(p);
	shm_init_task(p);
	security_task_alloc(p, clone_flags);

	copy_semundo(clone_flags, p);
	copy_files(clone_flags, p);
	copy_fs(clone_flags, p);
	copy_sighand(clone_flags, p);
	copy_signal(clone_flags, p);
	copy_mm(clone_flags, p);
	copy_namespaces(clone_flags, p);
	copy_io(clone_flags, p);
	copy_thread(p, args);

	stackleak_task_init(p);

	//pid相关

	p->plug

	futex_init_task(p);

	//sigaltstack should be cleared when sharing the same VM
	sas_ss_reset(p);

	user_disable_single_step(p);
	clear_task_syscall_work(p, SYSCALL_TRACE);
	clear_task_syscall_work(p, SYSCALL_EMU);
    
	clear_tsk_latency_tracing(p);

	p->pid
	p->group_leader
	p->tgid

	p->nr_dirtied
	p->nr_dirtied_pause
	p->dirty_paused_when

	p->pdeath_signal
	INIT_LIST_HEAD(&p->thread_group);
	p->task_works
	clear_posix_cputimers_work(p);

	p->kretprobe_instances.first

	p->rethooks.first

	//cgroup相关

	p->start_time
	p->start_boottime

	write_lock_irq(&tasklist_lock);

	p->real_parent
	p->parent_exec_id
	p->exit_signal

	klp_copy_process(p);

	sched_core_fork(p);

	copy_seccomp(p);

	rseq_fork(p, clone_flags);

	/* Don't start children in a dying pid namespace */
	if (unlikely(!(ns_of_pid(pid)->pid_allocated & PIDNS_ADDING))) {

	/* Let kill terminate clone/fork in the middle */
	fatal_signal_pending(current)

	//pid, thread_group相关
	
	hlist_del_init(&delayed.node);
	spin_unlock(&current->sighand->siglock);
	syscall_tracepoint_update(p);
	write_unlock_irq(&tasklist_lock);

	fd_install(pidfd, pidfile);

	proc_fork_connector(p);
	sched_post_fork(p);
	cgroup_post_fork(p, args);
	perf_event_fork(p);

	trace_task_newtask(p, clone_flags);
	uprobe_copy_process(p, clone_flags);

	copy_oom_score_adj(clone_flags, p);

	return p;

	//错误处理
}
----

===== fork与内存
创建mm_struct, vma等用于描述进程自己的地址空间，创建pgd页用于页表遍历时填充页表，然后拷贝父进程所有的vma，对于每个vma做页表的拷贝和写保护操作，其他各级页表(pud pmd等)的创建和填充工作由缺页异常处理来完成。

[source,c]
.https://elixir.bootlin.com/linux/latest/source/kernel/fork.c
----
static int copy_mm(unsigned long clone_flags, struct task_struct *tsk)
{
	struct mm_struct *mm, *oldmm;

	tsk->min_flt = tsk->maj_flt = 0;
	tsk->nvcsw = tsk->nivcsw = 0;
#ifdef CONFIG_DETECT_HUNG_TASK
	tsk->last_switch_count = tsk->nvcsw + tsk->nivcsw;
	tsk->last_switch_time = 0;
#endif

	tsk->mm = NULL;
	tsk->active_mm = NULL;

	/*
	 * Are we cloning a kernel thread?
	 *
	 * We need to steal a active VM for that..
	 */
	oldmm = current->mm;
	if (!oldmm)
		return 0; //内核线程(即当前进程地址空间为空)不需要为子进程做内存复制

	/* initialize the new vmacache entries */
	vmacache_flush(tsk);

	if (clone_flags & CLONE_VM) { //CLONE_VM置位，共享地址空间
		mmget(oldmm);
		mm = oldmm;
	} else { //CLONE_VM未置位，复制地址空间
		mm = dup_mm(tsk, current->mm);
		if (!mm)
			return -ENOMEM;
	}

	tsk->mm = mm;
	tsk->active_mm = mm;
	return 0;
}
----

复制地址空间即dup_mm实现了什么呢？

[source,c]
.https://elixir.bootlin.com/linux/latest/source/kernel/fork.c
----
static struct mm_struct *dup_mm(struct task_struct *tsk,
				struct mm_struct *oldmm)
{
	struct mm_struct *mm;
	int err;

	mm = allocate_mm(); //分配mm_struct
	if (!mm)
		goto fail_nomem;

	memcpy(mm, oldmm, sizeof(*mm));

	if (!mm_init(mm, tsk, mm->user_ns)) //初始化mm_struct
		goto fail_nomem;

	err = dup_mmap(mm, oldmm); //复制父进程地址空间
	if (err)
		goto free_pt;

	mm->hiwater_rss = get_mm_rss(mm);
	mm->hiwater_vm = mm->total_vm;

	if (mm->binfmt && !try_module_get(mm->binfmt->module))
		goto free_pt;

	return mm;

free_pt:
	/* don't put binfmt in mmput, we haven't got module yet */
	mm->binfmt = NULL;
	mm_init_owner(mm, NULL);
	mmput(mm);

fail_nomem:
	return NULL;
}

#ifdef CONFIG_MMU
static __latent_entropy int dup_mmap(struct mm_struct *mm,
					struct mm_struct *oldmm)
{
	struct vm_area_struct *mpnt, *tmp, *prev, **pprev;
	struct rb_node **rb_link, *rb_parent;
	int retval;
	unsigned long charge;
	LIST_HEAD(uf);

	uprobe_start_dup_mmap();
	if (mmap_write_lock_killable(oldmm)) {
		retval = -EINTR;
		goto fail_uprobe_end;
	}
	flush_cache_dup_mm(oldmm);
	uprobe_dup_mmap(oldmm, mm);
	/*
	 * Not linked in yet - no deadlock potential:
	 */
	mmap_write_lock_nested(mm, SINGLE_DEPTH_NESTING);

	/* No ordering required: file already has been exposed. */
	dup_mm_exe_file(mm, oldmm);

	mm->total_vm = oldmm->total_vm;
	mm->data_vm = oldmm->data_vm;
	mm->exec_vm = oldmm->exec_vm;
	mm->stack_vm = oldmm->stack_vm;

	rb_link = &mm->mm_rb.rb_node;
	rb_parent = NULL;
	pprev = &mm->mmap;
	retval = ksm_fork(mm, oldmm);
	if (retval)
		goto out;
	khugepaged_fork(mm, oldmm);

	prev = NULL;
	for (mpnt = oldmm->mmap; mpnt; mpnt = mpnt->vm_next) {
		struct file *file;

		if (mpnt->vm_flags & VM_DONTCOPY) {
			vm_stat_account(mm, mpnt->vm_flags, -vma_pages(mpnt));
			continue;
		}
		charge = 0;
		/*
		 * Don't duplicate many vmas if we've been oom-killed (for
		 * example)
		 */
		if (fatal_signal_pending(current)) {
			retval = -EINTR;
			goto out;
		}
		if (mpnt->vm_flags & VM_ACCOUNT) {
			unsigned long len = vma_pages(mpnt);

			if (security_vm_enough_memory_mm(oldmm, len)) /* sic */
				goto fail_nomem;
			charge = len;
		}
		tmp = vm_area_dup(mpnt);
		if (!tmp)
			goto fail_nomem;
		retval = vma_dup_policy(mpnt, tmp);
		if (retval)
			goto fail_nomem_policy;
		tmp->vm_mm = mm;
		retval = dup_userfaultfd(tmp, &uf);
		if (retval)
			goto fail_nomem_anon_vma_fork;
		if (tmp->vm_flags & VM_WIPEONFORK) {
			/*
			 * VM_WIPEONFORK gets a clean slate in the child.
			 * Don't prepare anon_vma until fault since we don't
			 * copy page for current vma.
			 */
			tmp->anon_vma = NULL;
		} else if (anon_vma_fork(tmp, mpnt))
			goto fail_nomem_anon_vma_fork;
		tmp->vm_flags &= ~(VM_LOCKED | VM_LOCKONFAULT);
		file = tmp->vm_file;
		if (file) {
			struct address_space *mapping = file->f_mapping;

			get_file(file);
			i_mmap_lock_write(mapping);
			if (tmp->vm_flags & VM_SHARED)
				mapping_allow_writable(mapping);
			flush_dcache_mmap_lock(mapping);
			/* insert tmp into the share list, just after mpnt */
			vma_interval_tree_insert_after(tmp, mpnt,
					&mapping->i_mmap);
			flush_dcache_mmap_unlock(mapping);
			i_mmap_unlock_write(mapping);
		}

		/*
		 * Clear hugetlb-related page reserves for children. This only
		 * affects MAP_PRIVATE mappings. Faults generated by the child
		 * are not guaranteed to succeed, even if read-only
		 */
		if (is_vm_hugetlb_page(tmp))
			reset_vma_resv_huge_pages(tmp);

		/*
		 * Link in the new vma and copy the page table entries.
		 */
		*pprev = tmp;
		pprev = &tmp->vm_next;
		tmp->vm_prev = prev;
		prev = tmp;

		__vma_link_rb(mm, tmp, rb_link, rb_parent);
		rb_link = &tmp->vm_rb.rb_right;
		rb_parent = &tmp->vm_rb;

		mm->map_count++;
		if (!(tmp->vm_flags & VM_WIPEONFORK))
			retval = copy_page_range(tmp, mpnt);//拷贝页面目录项及页面表项

		if (tmp->vm_ops && tmp->vm_ops->open)
			tmp->vm_ops->open(tmp);

		if (retval)
			goto out;
	}
	/* a new mm has just been created */
	retval = arch_dup_mmap(oldmm, mm);
out:
	mmap_write_unlock(mm);
	flush_tlb_mm(oldmm);
	mmap_write_unlock(oldmm);
	dup_userfaultfd_complete(&uf);
fail_uprobe_end:
	uprobe_end_dup_mmap();
	return retval;
fail_nomem_anon_vma_fork:
	mpol_put(vma_policy(tmp));
fail_nomem_policy:
	vm_area_free(tmp);
fail_nomem:
	retval = -ENOMEM;
	vm_unacct_memory(charge);
	goto out;
}

static inline int mm_alloc_pgd(struct mm_struct *mm)
{
	mm->pgd = pgd_alloc(mm);
	if (unlikely(!mm->pgd))
		return -ENOMEM;
	return 0;
}

static inline void mm_free_pgd(struct mm_struct *mm)
{
	pgd_free(mm, mm->pgd);
}
#else
static int dup_mmap(struct mm_struct *mm, struct mm_struct *oldmm)
{
	mmap_write_lock(oldmm);
	dup_mm_exe_file(mm, oldmm);
	mmap_write_unlock(oldmm);
	return 0;
}
#define mm_alloc_pgd(mm)	(0)
#define mm_free_pgd(mm)
#endif /* CONFIG_MMU */
----

参考: https://zhuanlan.zhihu.com/p/373954153

===== fork与进程

[source,c]
.https://elixir.bootlin.com/linux/latest/source/kernel/sched/core.c
----
//sched_fork主要是设置进程优先级，进程调度策略
int sched_fork(unsigned long clone_flags, struct task_struct *p)
{
	__sched_fork(clone_flags, p);
	/*
	 * We mark the process as NEW here. This guarantees that
	 * nobody will actually run it, and a signal or other external
	 * event cannot wake it up and insert it on the runqueue either.
	 */
	p->__state = TASK_NEW;

	/*
	 * Make sure we do not leak PI boosting priority to the child.
	 */
	p->prio = current->normal_prio;

	uclamp_fork(p);

	/*
	 * Revert to default priority/policy on fork if requested.
	 */
	if (unlikely(p->sched_reset_on_fork)) {
		if (task_has_dl_policy(p) || task_has_rt_policy(p)) {
			p->policy = SCHED_NORMAL;
			p->static_prio = NICE_TO_PRIO(0);
			p->rt_priority = 0;
		} else if (PRIO_TO_NICE(p->static_prio) < 0)
			p->static_prio = NICE_TO_PRIO(0);

		p->prio = p->normal_prio = p->static_prio;
		set_load_weight(p, false);

		/*
		 * We don't need the reset flag anymore after the fork. It has
		 * fulfilled its duty:
		 */
		p->sched_reset_on_fork = 0;
	}

	if (dl_prio(p->prio))
		return -EAGAIN;
	else if (rt_prio(p->prio))
		p->sched_class = &rt_sched_class;
	else
		p->sched_class = &fair_sched_class;

	init_entity_runnable_average(&p->se);


#ifdef CONFIG_SCHED_INFO
	if (likely(sched_info_on()))
		memset(&p->sched_info, 0, sizeof(p->sched_info));
#endif
#if defined(CONFIG_SMP)
	p->on_cpu = 0;
#endif
	init_task_preempt_count(p);
#ifdef CONFIG_SMP
	plist_node_init(&p->pushable_tasks, MAX_PRIO);
	RB_CLEAR_NODE(&p->pushable_dl_tasks);
#endif
	return 0;
}

/*
 * Perform scheduler related setup for a newly forked process p.
 * p is forked by current.
 *
 * __sched_fork() is basic setup used by init_idle() too:
 */
static void __sched_fork(unsigned long clone_flags, struct task_struct *p)
{
	p->on_rq			= 0;

	p->se.on_rq			= 0;
	p->se.exec_start		= 0;
	p->se.sum_exec_runtime		= 0;
	p->se.prev_sum_exec_runtime	= 0;
	p->se.nr_migrations		= 0;
	p->se.vruntime			= 0;
	INIT_LIST_HEAD(&p->se.group_node);

#ifdef CONFIG_FAIR_GROUP_SCHED
	p->se.cfs_rq			= NULL;
#endif

#ifdef CONFIG_SCHEDSTATS
	/* Even if schedstat is disabled, there should not be garbage */
	memset(&p->stats, 0, sizeof(p->stats));
#endif

	RB_CLEAR_NODE(&p->dl.rb_node);
	init_dl_task_timer(&p->dl);
	init_dl_inactive_task_timer(&p->dl);
	__dl_clear_params(p);

	INIT_LIST_HEAD(&p->rt.run_list);
	p->rt.timeout		= 0;
	p->rt.time_slice	= sched_rr_timeslice;
	p->rt.on_rq		= 0;
	p->rt.on_list		= 0;

#ifdef CONFIG_PREEMPT_NOTIFIERS
	INIT_HLIST_HEAD(&p->preempt_notifiers);
#endif

#ifdef CONFIG_COMPACTION
	p->capture_control = NULL;
#endif
	init_numa_balancing(clone_flags, p);
#ifdef CONFIG_SMP
	p->wake_entry.u_flags = CSD_TYPE_TTWU;
	p->migration_pending = NULL;
#endif
}
----

[source,c]
.https://elixir.bootlin.com/linux/latest/source/arch/x86/kernel/process.c
----
int copy_thread(struct task_struct *p, const struct kernel_clone_args *args)
{
	unsigned long clone_flags = args->flags;
	unsigned long sp = args->stack;
	unsigned long tls = args->tls;
	struct inactive_task_frame *frame;
	struct fork_frame *fork_frame;
	struct pt_regs *childregs;
	int ret = 0;

	childregs = task_pt_regs(p);
	fork_frame = container_of(childregs, struct fork_frame, regs);
	frame = &fork_frame->frame;

	frame->bp = encode_frame_pointer(childregs);
	frame->ret_addr = (unsigned long) ret_from_fork;
	p->thread.sp = (unsigned long) fork_frame;
	p->thread.io_bitmap = NULL;
	p->thread.iopl_warn = 0;
	memset(p->thread.ptrace_bps, 0, sizeof(p->thread.ptrace_bps));

#ifdef CONFIG_X86_64
	current_save_fsgs();
	p->thread.fsindex = current->thread.fsindex;
	p->thread.fsbase = current->thread.fsbase;
	p->thread.gsindex = current->thread.gsindex;
	p->thread.gsbase = current->thread.gsbase;

	savesegment(es, p->thread.es);
	savesegment(ds, p->thread.ds);
#else
	p->thread.sp0 = (unsigned long) (childregs + 1);
	savesegment(gs, p->thread.gs);
	/*
	 * Clear all status flags including IF and set fixed bit. 64bit
	 * does not have this initialization as the frame does not contain
	 * flags. The flags consistency (especially vs. AC) is there
	 * ensured via objtool, which lacks 32bit support.
	 */
	frame->flags = X86_EFLAGS_FIXED;
#endif

	fpu_clone(p, clone_flags, args->fn);

	/* Kernel thread ? */
	if (unlikely(p->flags & PF_KTHREAD)) {
		p->thread.pkru = pkru_get_init_value();
		memset(childregs, 0, sizeof(struct pt_regs));
		kthread_frame_init(frame, args->fn, args->fn_arg);
		return 0;
	}

	/*
	 * Clone current's PKRU value from hardware. tsk->thread.pkru
	 * is only valid when scheduled out.
	 */
	p->thread.pkru = read_pkru();

	frame->bx = 0;
	*childregs = *current_pt_regs();
	childregs->ax = 0;
	if (sp)
		childregs->sp = sp;

	if (unlikely(args->fn)) {
		/*
		 * A user space thread, but it doesn't return to
		 * ret_after_fork().
		 *
		 * In order to indicate that to tools like gdb,
		 * we reset the stack and instruction pointers.
		 *
		 * It does the same kernel frame setup to return to a kernel
		 * function that a kernel thread does.
		 */
		childregs->sp = 0;
		childregs->ip = 0;
		kthread_frame_init(frame, args->fn, args->fn_arg);
		return 0;
	}

	/* Set a new TLS for the child thread? */
	if (clone_flags & CLONE_SETTLS)
		ret = set_new_tls(p, tls);

	if (!ret && unlikely(test_tsk_thread_flag(current, TIF_IO_BITMAP)))
		io_bitmap_share(p);

	return ret;
}
----

参考: https://zhuanlan.zhihu.com/p/373958196

===== fork与文件
[source,c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h
----
struct task_struct {
    ......

	/* Filesystem information: */
	struct fs_struct		*fs;

	/* Open file information: */
	struct files_struct		*files;
    
    ......
};
----

struct fs_struct(文件系统信息):
[source,c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/fs_struct.h
----
struct fs_struct {
	int users;
	spinlock_t lock;
	seqcount_spinlock_t seq;
	int umask;
	int in_exec;
	struct path root, pwd;
} __randomize_layout;
----

struct files_struct(已打开文件的信息):
https://elixir.bootlin.com/linux/latest/source/include/linux/fdtable.h
[source,c]
----
struct fdtable {
	unsigned int max_fds;
	struct file __rcu **fd;      /* current fd array */
	unsigned long *close_on_exec;
	unsigned long *open_fds;
	unsigned long *full_fds_bits;
	struct rcu_head rcu;
};

//...

/*
 * Open file table structure
 */
struct files_struct {
  /*
   * read mostly part
   */
	atomic_t count;
	bool resize_in_progress;
	wait_queue_head_t resize_wait;

	struct fdtable __rcu *fdt;
	struct fdtable fdtab;
  /*
   * written part on a separate cache line in SMP
   */
	spinlock_t file_lock ____cacheline_aligned_in_smp;
	unsigned int next_fd;
	unsigned long close_on_exec_init[1];
	unsigned long open_fds_init[1];
	unsigned long full_fds_bits_init[1];
	struct file __rcu * fd_array[NR_OPEN_DEFAULT];
};
----

==== 0号进程的创建
0号进程对应init_task(注意，与1号进程即init进程区分)
之后演变成idle进程: 在smp系统中，每个处理器单元有独立的一个运行队列，每个运行队列上又有一个idle进程，因此有多少处理器单元，就有多少idle进程。 

0号进程结构体: struct task_struct init_task  https://elixir.bootlin.com/linux/latest/source/include/linux/init_task.h

0号进程堆栈:

	struct task_struct init_task
	{
	#ifdef CONFIG_THREAD_INFO_IN_TASK
		.thread_info	= INIT_THREAD_INFO(init_task),
	#endif
		.stack		= init_stack,

0号进程地址空间: struct mm_struct init_mm  https://elixir.bootlin.com/linux/latest/source/mm/init-mm.c

	struct task_struct init_task
	{
		......
		.mm		= NULL, //内核线程
		.active_mm	= &init_mm,
		......

0号进程演进:

    start_kernel: https://elixir.bootlin.com/linux/latest/source/init/main.c
        arch_call_rest_init()
            rest_init()

[source,c]
.rest_init(): https://elixir.bootlin.com/linux/latest/source/init/main.c
----
noinline void __ref rest_init(void)
{
	struct task_struct *tsk;
	int pid;

	rcu_scheduler_starting();
	/*
	 * We need to spawn init first so that it obtains pid 1, however
	 * the init task will end up wanting to create kthreads, which, if
	 * we schedule it before we create kthreadd, will OOPS.
	 */
	pid = user_mode_thread(kernel_init, NULL, CLONE_FS); //创建1号进程
	/*
	 * Pin init on the boot CPU. Task migration is not properly working
	 * until sched_init_smp() has been run. It will set the allowed
	 * CPUs for init to the non isolated CPUs.
	 */
	rcu_read_lock();
	tsk = find_task_by_pid_ns(pid, &init_pid_ns);
	tsk->flags |= PF_NO_SETAFFINITY;
	set_cpus_allowed_ptr(tsk, cpumask_of(smp_processor_id()));
	rcu_read_unlock();

	numa_default_policy();
	pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES); //创建2号进程
	rcu_read_lock();
	kthreadd_task = find_task_by_pid_ns(pid, &init_pid_ns);
	rcu_read_unlock();

	/*
	 * Enable might_sleep() and smp_processor_id() checks.
	 * They cannot be enabled earlier because with CONFIG_PREEMPTION=y
	 * kernel_thread() would trigger might_sleep() splats. With
	 * CONFIG_PREEMPT_VOLUNTARY=y the init task might have scheduled
	 * already, but it's stuck on the kthreadd_done completion.
	 */
	system_state = SYSTEM_SCHEDULING;

	complete(&kthreadd_done);

	/*
	 * The boot idle thread must execute schedule()
	 * at least once to get things moving:
	 */
	schedule_preempt_disabled();
	/* Call into cpu_idle with preempt disabled */
	cpu_startup_entry(CPUHP_ONLINE); //循环调用do_idle()
}
----

==== 1号进程的创建
init进程的创建:

    start_kernel()  https://elixir.bootlin.com/linux/latest/source/init/main.c
        arch_call_rest_init()
            rest_init()
                pid = user_mode_thread(kernel_init, NULL, CLONE_FS);

注意，kernel_init内核进程会演变成用户进程

==== 2号进程的创建
kthreadd的创建:

    start_kernel()  https://elixir.bootlin.com/linux/latest/source/init/main.c
        arch_call_rest_init()
            rest_init()
                pid = kernel_thread(kthreadd, NULL, CLONE_FS | CLONE_FILES);

==== v0.12
fork

    fork()  https://elixir.bootlin.com/linux/0.12/source/include/unistd.h
        sys_fork()  https://elixir.bootlin.com/linux/0.12/source/kernel/sys_call.s
            copy_process()  https://elixir.bootlin.com/linux/0.12/source/kernel/fork.c

=== 启动新程序
https://elixir.bootlin.com/linux/latest/source/fs/exec.c

    do_execve()
        do_execveat_common()
            bprm_execve()
                exec_binprm()
                    search_binary_handler()
                        load_binary(struct linux_binprm *bprm)
                            load_elf_binary(): https://elixir.bootlin.com/linux/latest/source/fs/binfmt_elf.c
                                start_thread(): https://elixir.bootlin.com/linux/latest/source/arch/x86/kernel/process_32.c
                                    start_thread_common: https://elixir.bootlin.com/linux/latest/source/arch/x86/kernel/process_64.c

[source,assembly]
.https://elixir.bootlin.com/linux/latest/source/include/linux/binfmts.h
----
/*
 * This structure is used to hold the arguments that are used when loading binaries.
 */
struct linux_binprm {
#ifdef CONFIG_MMU
	struct vm_area_struct *vma;
	unsigned long vma_pages;
#else
# define MAX_ARG_PAGES	32
	struct page *page[MAX_ARG_PAGES];
#endif
	struct mm_struct *mm;
	unsigned long p; /* current top of mem */
	unsigned long argmin; /* rlimit marker for copy_strings() */
	unsigned int
		/* Should an execfd be passed to userspace? */
		have_execfd:1,

		/* Use the creds of a script (see binfmt_misc) */
		execfd_creds:1,
		/*
		 * Set by bprm_creds_for_exec hook to indicate a
		 * privilege-gaining exec has happened. Used to set
		 * AT_SECURE auxv for glibc.
		 */
		secureexec:1,
		/*
		 * Set when errors can no longer be returned to the
		 * original userspace.
		 */
		point_of_no_return:1;
#ifdef __alpha__
	unsigned int taso:1;
#endif
	struct file *executable; /* Executable to pass to the interpreter */
	struct file *interpreter;
	struct file *file;
	struct cred *cred;	/* new credentials */
	int unsafe;		/* how unsafe this exec is (mask of LSM_UNSAFE_*) */
	unsigned int per_clear;	/* bits to clear in current->personality */
	int argc, envc;
	const char *filename;	/* Name of binary as seen by procps */
	const char *interp;	/* Name of the binary really executed. Most
				   of the time same as filename, but could be
				   different for binfmt_{misc,script} */
	const char *fdpath;	/* generated filename for execveat */
	unsigned interp_flags;
	int execfd;		/* File descriptor of the executable */
	unsigned long loader, exec;

	struct rlimit rlim_stack; /* Saved RLIMIT_STACK used during exec. */

	char buf[BINPRM_BUF_SIZE];
} __randomize_layout;
----

=== 退出
https://elixir.bootlin.com/linux/latest/source/kernel/exit.c

SYSCALL_DEFINE1(exit, int, error_code):
    do_exit()

SYSCALL_DEFINE4(wait4, pid_t, upid, int __user *, stat_addr, int, options, struct rusage __user *, ru):
    kernel_wait4()

=== 内核线程
内核线程是一种只运行在内核地址空间的线程。
所有的内核线程共享内核地址空间(对于32 位系统来说，就是3-4GB的虚拟地址空间)，所以也共享同一份内核页表。这也是为什么叫内核线程，而不叫内核进程的原因。

==== 结构
struct kthread: https://elixir.bootlin.com/linux/latest/source/kernel/kthread.c

==== 操作
copy_thread(): https://elixir.bootlin.com/linux/latest/source/arch/x86/kernel/process.c
    
    PF_KTHREAD

除了初始化阶段0号内核线程和kthreadd，其它所有内核线程都是由kthreadd内核线程来创建的

    int kthreadd(void *unused)  https://elixir.bootlin.com/linux/latest/source/kernel/kthread.c
        create_kthread()  https://elixir.bootlin.com/linux/latest/source/kernel/kthread.c
            kernel_thread()  https://elixir.bootlin.com/linux/latest/source/kernel/fork.c
                kernel_clone()  https://elixir.bootlin.com/linux/latest/source/kernel/fork.c

kthread_run(): https://elixir.bootlin.com/linux/latest/source/include/linux/kthread.h

	kthread_create()
	wake_up_process()

kthread_stop(): https://elixir.bootlin.com/linux/latest/source/kernel/kthread.c

==== 内核线程虚拟地址转换
https://zhuanlan.zhihu.com/p/373959024
https://mp.weixin.qq.com/s/pmWuGS6thCj6GNwwjh0bRw

==== 示例
- kswapd
kswapd_run()  https://elixir.bootlin.com/linux/latest/source/mm/vmscan.c

- ksoftirqd
https://elixir.bootlin.com/linux/latest/source/kernel/softirq.c

static struct smp_hotplug_thread softirq_threads = {
        .store                  = &ksoftirqd,
        .thread_should_run      = ksoftirqd_should_run,
        .thread_fn              = run_ksoftirqd,
        .thread_comm            = "ksoftirqd/%u",
};  

=== 命名空间
==== 概念与作用
隔离资源
https://en.wikipedia.org/wiki/Linux_namespaces

==== 演进
2.4: mount
2.6: IPC Network PID UTS
2.6-3.8: User
4.6: Cgroup

==== 结构

[source,c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/nsproxy.h
----
struct nsproxy {
	atomic_t count;
	struct uts_namespace *uts_ns;                //CLONE_NEWUTS
	struct ipc_namespace *ipc_ns;                //CLONE_NEWIPC
	struct mnt_namespace *mnt_ns;                //CLONE_NEWNS
	struct pid_namespace *pid_ns_for_children;   //CLONE_NEWPID
	struct net 	     *net_ns;                    //CLONE_NEWNET
	struct time_namespace *time_ns;              //CLONE_NEWTIME
	struct time_namespace *time_ns_for_children;
	struct cgroup_namespace *cgroup_ns;          //CLONE_NEWCGROUP
};
----

=== 进程ID

[source,c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/pid.h
----
enum pid_type
{
	PIDTYPE_PID,
	PIDTYPE_TGID,
	PIDTYPE_PGID,
	PIDTYPE_SID,
	PIDTYPE_MAX,
};

/*
 * What is struct pid?
 *
 * A struct pid is the kernel's internal notion of a process identifier.
 * It refers to individual tasks, process groups, and sessions.  While
 * there are processes attached to it the struct pid lives in a hash
 * table, so it and then the processes that it refers to can be found
 * quickly from the numeric pid value.  The attached processes may be
 * quickly accessed by following pointers from struct pid.
 *
 * Storing pid_t values in the kernel and referring to them later has a
 * problem.  The process originally with that pid may have exited and the
 * pid allocator wrapped, and another process could have come along
 * and been assigned that pid.
 *
 * Referring to user space processes by holding a reference to struct
 * task_struct has a problem.  When the user space process exits
 * the now useless task_struct is still kept.  A task_struct plus a
 * stack consumes around 10K of low kernel memory.  More precisely
 * this is THREAD_SIZE + sizeof(struct task_struct).  By comparison
 * a struct pid is about 64 bytes.
 *
 * Holding a reference to struct pid solves both of these problems.
 * It is small so holding a reference does not consume a lot of
 * resources, and since a new struct pid is allocated when the numeric pid
 * value is reused (when pids wrap around) we don't mistakenly refer to new
 * processes.
 */


/*
 * struct upid is used to get the id of the struct pid, as it is
 * seen in particular namespace. Later the struct pid is found with
 * find_pid_ns() using the int nr and struct pid_namespace *ns.
 */

struct upid {
	int nr;
	struct pid_namespace *ns;
};

struct pid
{
	refcount_t count;
	unsigned int level;
	spinlock_t lock;
	/* lists of tasks that use this pid */
	struct hlist_head tasks[PIDTYPE_MAX];
	struct hlist_head inodes;
	/* wait queue for pidfd notifications */
	wait_queue_head_t wait_pidfd;
	struct rcu_head rcu;
	struct upid numbers[1];
};
----

进程的PID和TGID位于task_struct,
PGID和SID则位于task_struct->signal:
struct signal_struct {
    ...
	/* PID/PID hash table linkage. */
	struct pid *pids[PIDTYPE_MAX];
    ...
}

全局ID:

    struct task_struct {
        ...
        pid_t   pid;  //可以理解为线程ID或任务ID
        pid_t   tgid; //可以理解为进程ID或线程组ID
        ...
    }

局部ID:

    属于某个特定的命名空间，不具备全局有效性

struct pid_namespace: https://elixir.bootlin.com/linux/latest/source/include/linux/pid_namespace.h

创建:
alloc_pid()
    调用时机: copy_process()

销毁:
free_pid()
    调用时机: __change_pid()

大小:
int pid_max = PID_MAX_DEFAULT; https://elixir.bootlin.com/linux/latest/source/kernel/pid.c
#define PID_MAX_DEFAULT (CONFIG_BASE_SMALL ? 0x1000 : 0x8000) https://elixir.bootlin.com/linux/latest/source/include/linux/threads.h