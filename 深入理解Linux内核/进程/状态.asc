:toc:
:toclevels: 5
:hardbreaks-option:

== 状态

=== TASK状态
==== 类型
[source, c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/sched.h
----
/* Used in tsk->__state: */
#define TASK_RUNNING			0x00000000
#define TASK_INTERRUPTIBLE		0x00000001
#define TASK_UNINTERRUPTIBLE		0x00000002
#define __TASK_STOPPED			0x00000004
#define __TASK_TRACED			0x00000008
/* Used in tsk->exit_state: */
#define EXIT_DEAD			0x00000010
#define EXIT_ZOMBIE			0x00000020
#define EXIT_TRACE			(EXIT_ZOMBIE | EXIT_DEAD)
/* Used in tsk->__state again: */
#define TASK_PARKED			0x00000040
#define TASK_DEAD			0x00000080
#define TASK_WAKEKILL			0x00000100
#define TASK_WAKING			0x00000200
#define TASK_NOLOAD			0x00000400
#define TASK_NEW			0x00000800
#define TASK_RTLOCK_WAIT		0x00001000
#define TASK_FREEZABLE			0x00002000
#define __TASK_FREEZABLE_UNSAFE	       (0x00004000 * IS_ENABLED(CONFIG_LOCKDEP))
#define TASK_FROZEN			0x00008000
#define TASK_STATE_MAX			0x00010000

#define TASK_ANY			(TASK_STATE_MAX-1)

/*
 * DO NOT ADD ANY NEW USERS !
 */
#define TASK_FREEZABLE_UNSAFE		(TASK_FREEZABLE | __TASK_FREEZABLE_UNSAFE)

/* Convenience macros for the sake of set_current_state: */
#define TASK_KILLABLE			(TASK_WAKEKILL | TASK_UNINTERRUPTIBLE)
#define TASK_STOPPED			(TASK_WAKEKILL | __TASK_STOPPED)
#define TASK_TRACED			__TASK_TRACED

#define TASK_IDLE			(TASK_UNINTERRUPTIBLE | TASK_NOLOAD)

/* Convenience macros for the sake of wake_up(): */
#define TASK_NORMAL			(TASK_INTERRUPTIBLE | TASK_UNINTERRUPTIBLE)

/* get_task_state(): */
#define TASK_REPORT			(TASK_RUNNING | TASK_INTERRUPTIBLE | \
					 TASK_UNINTERRUPTIBLE | __TASK_STOPPED | \
					 __TASK_TRACED | EXIT_DEAD | EXIT_ZOMBIE | \
					 TASK_PARKED)

#define task_is_running(task)		(READ_ONCE((task)->__state) == TASK_RUNNING)

#define task_is_traced(task)		((READ_ONCE(task->jobctl) & JOBCTL_TRACED) != 0)
#define task_is_stopped(task)		((READ_ONCE(task->jobctl) & JOBCTL_STOPPED) != 0)
#define task_is_stopped_or_traced(task)	((READ_ONCE(task->jobctl) & (JOBCTL_STOPPED | JOBCTL_TRACED)) != 0)
----

- TASK_RUNNING

    正在运行或可以运行(即就绪)
    对应ps命令里的R: running or runnable (on run queue)

- TASK_INTERRUPTIBLE

    可中断睡眠状态：即使其等待的某特定事件没有发生，也是可以被唤醒的
    对应ps命令里的S: interruptible sleep (waiting for an event to complete)
    Q: 哪些操作会导致task进入TASK_INTERRUPTIBLE状态？
    A: 例如nanosleep()系统调用

- TASK_UNINTERRUPTIBLE

    不可中断睡眠状态：必须等到某特定事件发生后才能被唤醒
    对应ps命令里的D: uninterruptible sleep (usually IO)
    Q: 哪些操作会导致task进入TASK_UNINTERRUPTIBLE状态？
    A: 例如select()系统调用

- __TASK_STOPPED

    停止状态
    进程收到SIGTOP/SIGTTIN/SIGTSTP/SIGTTOU等信号会进入该状态
    对应ps命令里的T: stopped by job control signal

- __TASK_TRACED

    停止状态
    被debugger调试停止
    对应ps命令里的t: stopped by debugger during the tracing

- EXIT_DEAD

    资源已被父进程回收，进程结束
    对应ps命令里的X: dead (should never be seen)

- EXIT_ZOMBIE

    进程结束前先进入该状态，等待父进程释放某些资源
    对应ps命令里的Z: defunct ("zombie") process, terminated but not reaped by its parent

- TASK_PARKED

    __kthread_parkme(): https://elixir.bootlin.com/linux/latest/source/kernel/kthread.c
    对应ps命令里的P: park机制的主要作用是支持cpu hotplug

==== 状态转换
image:https://www.baeldung.com/wp-content/uploads/sites/2/2021/10/p1.jpeg[]
.Image source: https://www.baeldung.com/wp-content/uploads/sites/2/2021/10/p1.jpeg[window=read-later]

参考: https://access.redhat.com/sites/default/files/attachments/processstates_20120831.pdf

==== 显示
[source, c]
.https://elixir.bootlin.com/linux/latest/source/fs/proc/array.c
----
/*
 * The task state array is a strange "bitmap" of
 * reasons to sleep. Thus "running" is zero, and
 * you can test for combinations of others with
 * simple bit tests.
 */
static const char * const task_state_array[] = {

	/* states in TASK_REPORT: */
	"R (running)",		/* 0x00 */
	"S (sleeping)",		/* 0x01 */
	"D (disk sleep)",	/* 0x02 */
	"T (stopped)",		/* 0x04 */
	"t (tracing stop)",	/* 0x08 */
	"X (dead)",		/* 0x10 */
	"Z (zombie)",		/* 0x20 */
	"P (parked)",		/* 0x40 */

	/* states beyond TASK_REPORT: */
	"I (idle)",		/* 0x80 */
};
----

由get_task_state(struct task_struct *tsk)函数使用，用于显示进程状态。

=== 内核态与用户态
==== 概念
- 概念

    内核态用户态指的是CPU在执行指令时所位于的特权层级
    Q: 内核态能访问用户空间的buffer吗？

- 作用: 稳定性与安全性

- 特权级(privilege level)

    x86 CPU hardware actually provides four protection rings: 0, 1, 2, and 3.
        Only rings 0 (Kernel) and 3 (User) are typically used.
        CPL DPL RPL: 这三个特权级均由两位bit组成，可以表示0～3共4个等级。
        CPL: current privilege level，存放在代码段寄存器中(CS)，表示当前执行程序的特权级。
        RPL: request privilege level，请求特权级，存放在段选择子中。
        DPL: descriptor privilege level，存放在段描述符中，表示段的特权级。
        在保护模式下，CPU利用CPL/RPL/DPL对程序的访问操作进行特权级检查，数据段和代码段的特权级检查规则有所不同。

    ARM64中特权级的概念称为异常级别(EL, exception level)，其异常级别被划分为四个等级，特权也从低到高:
        EL0: 通常用户程序，对应用户态
        EL1: 操作系统内核，对应内核态
        EL2: Supervisor模式，用于虚拟机监视与扩展
        EL3: Secure Monitor模式，用于安全监控

- 切换

    ▪ 系统调用
    ▪ 中断
    ▪ 异常

- 每个处理器在任何指定时间上的活动必然为以下之一:

    ▪ 运行在用户空间，执行用户进程
    ▪ 运行在内核空间，处于进程上下文，代表某个特定的进程或内核线程的执行
    ▪ 运行在内核空间，处于中断上下文，与任何进程无关，处理某个特定的中断

- 如何判定当前是在用户态还是内核态

    task_struct->mm为空：内核态，否则为用户态

==== exit_to_user_mode_prepare()
===== 调用时机
系统调用返回: 
syscall_exit_to_user_mode_work(): https://elixir.bootlin.com/linux/latest/source/include/linux/entry-common.h

中断返回:
irqentry_exit_to_user_mode(): https://elixir.bootlin.com/linux/latest/source/kernel/entry/common.c

===== 实现
[source, c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/irq-entry-common.h
----
/**
 * exit_to_user_mode_prepare - call exit_to_user_mode_loop() if required
 * @regs:	Pointer to pt_regs on entry stack
 *
 * 1) check that interrupts are disabled
 * 2) call tick_nohz_user_enter_prepare()
 * 3) call exit_to_user_mode_loop() if any flags from
 *    EXIT_TO_USER_MODE_WORK are set
 * 4) check that interrupts are still disabled
 */
static __always_inline void exit_to_user_mode_prepare(struct pt_regs *regs)
{
	unsigned long ti_work;

	lockdep_assert_irqs_disabled();

	/* Flush pending rcuog wakeup before the last need_resched() check */
	tick_nohz_user_enter_prepare();

	ti_work = read_thread_flags();
	if (unlikely(ti_work & EXIT_TO_USER_MODE_WORK))
		ti_work = exit_to_user_mode_loop(regs, ti_work);

	arch_exit_to_user_mode_prepare(regs, ti_work);

	/* Ensure that kernel state is sane for a return to userspace */
	kmap_assert_nomap();
	lockdep_assert_irqs_disabled();
	lockdep_sys_exit();
}
----
核心函数: exit_to_user_mode_loop()

==== exit_to_user_mode_loop()
[source, c]
.https://elixir.bootlin.com/linux/latest/source/kernel/entry/common.c
----
/**
 * exit_to_user_mode_loop - do any pending work before leaving to user space
 * @regs:	Pointer to pt_regs on entry stack
 * @ti_work:	TIF work flags as read by the caller
 */
__always_inline unsigned long exit_to_user_mode_loop(struct pt_regs *regs,
						     unsigned long ti_work)
{
	/*
	 * Before returning to user space ensure that all pending work
	 * items have been completed.
	 */
	while (ti_work & EXIT_TO_USER_MODE_WORK) {

		local_irq_enable_exit_to_user(ti_work);

		if (ti_work & (_TIF_NEED_RESCHED | _TIF_NEED_RESCHED_LAZY))
			schedule();

		if (ti_work & _TIF_UPROBE)
			uprobe_notify_resume(regs);

		if (ti_work & _TIF_PATCH_PENDING)
			klp_update_patch_state(current);

		if (ti_work & (_TIF_SIGPENDING | _TIF_NOTIFY_SIGNAL))
			arch_do_signal_or_restart(regs);

		if (ti_work & _TIF_NOTIFY_RESUME)
			resume_user_mode_work(regs);

		/* Architecture specific TIF work */
		arch_exit_to_user_mode_work(regs, ti_work);

		/*
		 * Disable interrupts and reevaluate the work flags as they
		 * might have changed while interrupts and preemption was
		 * enabled above.
		 */
		local_irq_disable_exit_to_user();

		/* Check if any of the above work has queued a deferred wakeup */
		tick_nohz_user_enter_prepare();

		ti_work = read_thread_flags();
	}

	/* Return the latest work state for arch_exit_to_user_mode() */
	return ti_work;
}
----
schedule(): 处理调度
arch_do_signal_or_restart(regs): 处理信号

=== 上下文
==== 接口
[source, c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/preempt.h
----
/*
 * We put the hardirq and softirq counter into the preemption
 * counter. The bitmask has the following meaning:
 *
 * - bits 0-7 are the preemption count (max preemption depth: 256)
 * - bits 8-15 are the softirq count (max # of softirqs: 256)
 *
 * The hardirq count could in theory be the same as the number of
 * interrupts in the system, but we run all interrupt handlers with
 * interrupts disabled, so we cannot have nesting interrupts. Though
 * there are a few palaeontologic drivers which reenable interrupts in
 * the handler, so we need more than one bit here.
 *
 *         PREEMPT_MASK:	0x000000ff
 *         SOFTIRQ_MASK:	0x0000ff00
 *         HARDIRQ_MASK:	0x000f0000
 *             NMI_MASK:	0x00f00000
 * PREEMPT_NEED_RESCHED:	0x80000000
 */
//...
/*
 * Macros to retrieve the current execution context:
 *
 * in_nmi()		- We're in NMI context
 * in_hardirq()		- We're in hard IRQ context
 * in_serving_softirq()	- We're in softirq context
 * in_task()		- We're in task context
 */
#define in_nmi()		(nmi_count())
#define in_hardirq()		(hardirq_count())
#define in_serving_softirq()	(softirq_count() & SOFTIRQ_OFFSET)
#ifdef CONFIG_PREEMPT_RT
# define in_task()		(!((preempt_count() & (NMI_MASK | HARDIRQ_MASK)) | in_serving_softirq()))
#else
# define in_task()		(!(preempt_count() & (NMI_MASK | HARDIRQ_MASK | SOFTIRQ_OFFSET)))
#endif

/*
 * The following macros are deprecated and should not be used in new code:
 * in_irq()       - Obsolete version of in_hardirq()
 * in_softirq()   - We have BH disabled, or are processing softirqs
 * in_interrupt() - We're in NMI,IRQ,SoftIRQ context or have BH disabled
 */
#define in_irq()		(hardirq_count())
#define in_softirq()		(softirq_count())
#define in_interrupt()		(irq_count())

//...

/*
 * Are we running in atomic context?  WARNING: this macro cannot
 * always detect atomic context; in particular, it cannot know about
 * held spinlocks in non-preemptible kernels.  Thus it should not be
 * used in the general case to determine whether sleeping is possible.
 * Do not use in_atomic() in driver code.
 */
#define in_atomic()	(preempt_count() != 0)
----

==== 中断上下文
- 概念
中断上下文是内核在处理硬件中断时所处的环境。它是异步的，与任何特定的进程无关。

- 触发时机
硬件设备需要CPU关注时（如网络包到达、磁盘IO完成、定时器到期）。

- 核心特点
** 与进程无关: 中断处理程序不知道也不关心当前正在运行的是哪个进程。它无法访问当前进程的地址空间。
** 不可睡眠/不可调度: 中断上下文中的代码绝对不能睡眠或放弃CPU。因为中断上下文不属于任何一个进程，如果它睡眠了，就没有进程可以唤醒它，最终会导致内核崩溃。
** 执行要迅速: 中断处理程序应该尽快完成，因为它会抢占其它代码(包括进程上下文和其它中断)，长时间的中断处理会导致系统响应延迟和性能问题。

- 注意事项
只能调用不会睡眠的函数。
所有内存分配必须使用 GFP_ATOMIC 标志。
不能调用 copy_to_user() / copy_from_user()，因为与用户空间无关。

==== task上下文/进程上下文
- in_task()

- 特点
** 与进程关联: 内核代码可以访问进程的地址空间、进程的task_struct结构体等。
** 可以睡眠/调度: 处于进程上下文的内核代码是可以睡眠的。如果需要等待某个资源，它可以调用schedule()主动放弃CPU，或者被更高优先级的进程抢占。当资源就绪后，它会被重新调度执行。
** 可以被抢占: 因为内核有抢占功能，所以进程上下文中的内核路径可能会被另一个更高优先级的进程中断。
** 可以调用可能引起睡眠的函数，如 kmalloc(GFP_KERNEL)/copy_from_user()/msleep() 等。

==== atomic上下文
- in_atomic()
WARNING: this macro cannot always detect atomic context; in particular, it cannot know about held spinlocks in non-preemptible kernels.

- 概念
** 原子上下文是一个更宽泛的概念，它描述的是一种内核代码执行的状态，在这种状态下，代码不能被睡眠或调度出去。
** 原子上下文包括了中断上下文，但不限于中断上下文。
** 除了中断上下文，以下情况也属于原子上下文：
*** 持有自旋锁时: 获得一个自旋锁后，就进入了原子上下文。这是因为自旋锁是用来在SMP系统上保护短临界区的，如果持有锁时睡眠了，另一个CPU可能会无限期地等待这个锁，导致死锁。
*** 关抢占时: 通过 preempt_disable() 显式关闭抢占后。

- 特点
** 不可睡眠: 和中断上下文一样，不能调用任何可能导致睡眠的函数或内存分配(GFP_KERNEL)。
** 不可被抢占: 在原子上下文中，内核的抢占被暂时禁用，保证了代码段的原子执行。

- 参考
https://lwn.net/Articles/274695/