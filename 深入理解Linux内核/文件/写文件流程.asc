:toc:
:toclevels: 5
:hardbreaks-option:

== 写文件流程

=== 过程概述

=== write()系统调用
[source, c]
.https://elixir.bootlin.com/linux/latest/source/fs/read_write.c
----
ssize_t ksys_write(unsigned int fd, const char __user *buf, size_t count)
{
	struct fd f = fdget_pos(fd);
	ssize_t ret = -EBADF;

	if (f.file) {
		loff_t pos, *ppos = file_ppos(f.file);
		if (ppos) {
			pos = *ppos;
			ppos = &pos;
		}
		ret = vfs_write(f.file, buf, count, ppos);
		if (ret >= 0 && ppos)
			f.file->f_pos = pos;
		fdput_pos(f);
	}

	return ret;
}

SYSCALL_DEFINE3(write, unsigned int, fd, const char __user *, buf,
		size_t, count)
{
	return ksys_write(fd, buf, count);
}
----
可见，write()最终调用vfs_write():

=== vfs_write()
[source, c]
.https://elixir.bootlin.com/linux/latest/source/fs/read_write.c
----
ssize_t vfs_write(struct file *file, const char __user *buf, size_t count, loff_t *pos)
{
	//...
	if (file->f_op->write)
		ret = file->f_op->write(file, buf, count, pos);
	else if (file->f_op->write_iter)
		ret = new_sync_write(file, buf, count, pos);
	else
		ret = -EINVAL;
	//...
}
----
如果file->f_op->write函数存在，调用file->f_op->write();
否则如果file->f_op->write_iter存在，调用new_sync_write()。

目前大多数文件系统都是使用新的file->f_op->write_iter函数。
write_iter和write的区别是，write_iter一次性可以读取多个文件片段:
write_iter使用了(struct kiocb *, struct iov_iter *)参数。

[source, c]
.https://elixir.bootlin.com/linux/latest/source/fs/read_write.c
----
static ssize_t new_sync_write(struct file *filp, const char __user *buf, size_t len, loff_t *ppos)
{
	struct kiocb kiocb;
	struct iov_iter iter;
	ssize_t ret;

	init_sync_kiocb(&kiocb, filp);
	kiocb.ki_pos = (ppos ? *ppos : 0);
	iov_iter_ubuf(&iter, ITER_SOURCE, (void __user *)buf, len);

	ret = call_write_iter(filp, &kiocb, &iter);
	BUG_ON(ret == -EIOCBQUEUED);
	if (ret > 0 && ppos)
		*ppos = kiocb.ki_pos;
	return ret;
}
----

[source, c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/fs.h
----
static inline ssize_t call_write_iter(struct file *file, struct kiocb *kio,
				      struct iov_iter *iter)
{
	return file->f_op->write_iter(kio, iter);
}
----
可见，new_sync_write()调用call_write_iter函数, 最终调用struct file_operations里的:
ssize_t (*write_iter) (struct kiocb *, struct iov_iter *);

对于ext4文件系统，这个file_operations即为ext4_file_operations，这个write_iter函数指针指向ext4_file_write_iter函数():

[source, c]
.https://elixir.bootlin.com/linux/latest/source/fs/ext4/file.c
----
const struct file_operations ext4_file_operations = {
	//...
	.write_iter	= ext4_file_write_iter,
	//...
};
----

=== ext4_file_write_iter()
[source, c]
.https://elixir.bootlin.com/linux/latest/source/fs/ext4/file.c
----
static ssize_t
ext4_file_write_iter(struct kiocb *iocb, struct iov_iter *from)
{
	struct inode *inode = file_inode(iocb->ki_filp);

	if (unlikely(ext4_forced_shutdown(inode->i_sb)))
		return -EIO;

#ifdef CONFIG_FS_DAX
	if (IS_DAX(inode))
		return ext4_dax_write_iter(iocb, from);
#endif
	if (iocb->ki_flags & IOCB_DIRECT)
		return ext4_dio_write_iter(iocb, from);
	else
		return ext4_buffered_write_iter(iocb, from);
}
----
可见，ext4_file_write_iter()与ext4_file_read_iter()是类似的。

磁盘(disk)的访问模式有三种: BUFFERED、DIRECT与DAX。
BUFFERED是通常使用的模式，即使用内核缓冲区。
DIRECT是直接IO，直接访问磁盘数据，不经过内核缓冲区。直接I/O的特点是去除了缓存的复制环节，降低了文件读取和写入时CPU的利用率。在有非常低的高速缓存命中率文件数据，或者需要自己定制缓存策略等场景下使用。
DAX用于memory-like的块设备(例如NVDIMM), 也是一种去除了额外拷贝的直接模式。

抛开DAX与IOCB_DIRECT，ext4_buffered_write_iter函数就是通常的主流程了(对应BUFFERED模式):

=== ext4_buffered_write_iter()
[source, c]
.https://elixir.bootlin.com/linux/latest/source/fs/ext4/file.c
----
static ssize_t ext4_buffered_write_iter(struct kiocb *iocb,
					struct iov_iter *from)
{
	ssize_t ret;
	struct inode *inode = file_inode(iocb->ki_filp);

	if (iocb->ki_flags & IOCB_NOWAIT)
		return -EOPNOTSUPP;

	inode_lock(inode);
	ret = ext4_write_checks(iocb, from);
	if (ret <= 0)
		goto out;

	ret = generic_perform_write(iocb, from);

out:
	inode_unlock(inode);
	if (unlikely(ret <= 0))
		return ret;
	return generic_write_sync(iocb, ret);
}
----
generic_write_sync(): 同步缓存到磁盘(在具备同步刷写属性的情况下)。

因此，generic_perform_write()是核心流程():

=== generic_perform_write()
[source, c]
.https://elixir.bootlin.com/linux/latest/source/mm/filemap.c
----
ssize_t generic_perform_write(struct kiocb *iocb, struct iov_iter *i)
{
	struct file *file = iocb->ki_filp;
	loff_t pos = iocb->ki_pos;
	struct address_space *mapping = file->f_mapping;
	const struct address_space_operations *a_ops = mapping->a_ops;
	long status = 0;
	ssize_t written = 0;

	do {
		struct page *page;
		unsigned long offset;	/* Offset into pagecache page */
		unsigned long bytes;	/* Bytes to write to page */
		size_t copied;		/* Bytes copied from user */
		void *fsdata = NULL;

		offset = (pos & (PAGE_SIZE - 1));
		bytes = min_t(unsigned long, PAGE_SIZE - offset,
						iov_iter_count(i));

again:
		/*
		 * Bring in the user page that we will copy from _first_.
		 * Otherwise there's a nasty deadlock on copying from the
		 * same page as we're writing to, without it being marked
		 * up-to-date.
		 */
		if (unlikely(fault_in_iov_iter_readable(i, bytes) == bytes)) {
			status = -EFAULT;
			break;
		}

		if (fatal_signal_pending(current)) {
			status = -EINTR;
			break;
		}

		status = a_ops->write_begin(file, mapping, pos, bytes,
						&page, &fsdata);
		if (unlikely(status < 0))
			break;

		if (mapping_writably_mapped(mapping))
			flush_dcache_page(page);

		copied = copy_page_from_iter_atomic(page, offset, bytes, i);
		flush_dcache_page(page);

		status = a_ops->write_end(file, mapping, pos, bytes, copied,
						page, fsdata);
		if (unlikely(status != copied)) {
			iov_iter_revert(i, copied - max(status, 0L));
			if (unlikely(status < 0))
				break;
		}
		cond_resched();

		if (unlikely(status == 0)) {
			/*
			 * A short copy made ->write_end() reject the
			 * thing entirely.  Might be memory poisoning
			 * halfway through, might be a race with munmap,
			 * might be severe memory pressure.
			 */
			if (copied)
				bytes = copied;
			goto again;
		}
		pos += status;
		written += status;

		balance_dirty_pages_ratelimited(mapping);
	} while (iov_iter_count(i));

	if (!written)
		return status;
	iocb->ki_pos += written;
	return written;
}
----
执行循环，直到所有的内容写入完成:
	调用a_ops->write_begin, 对于ext4, 即为ext4_write_begin()
	把需要写的内容写到page cache
	调用a_ops->write_end, 对于ext4, 即为ext4_write_end()

ext4_write_begin()与ext4_write_end():
https://elixir.bootlin.com/linux/latest/source/fs/ext4/inode.c

=== generic_write_sync()
[source, c]
.https://elixir.bootlin.com/linux/latest/source/include/linux/fs.h
----
/*
 * Sync the bytes written if this was a synchronous write.  Expect ki_pos
 * to already be updated for the write, and will return either the amount
 * of bytes passed in, or an error if syncing the file failed.
 */
static inline ssize_t generic_write_sync(struct kiocb *iocb, ssize_t count)
{
	if (iocb_is_dsync(iocb)) {
		int ret = vfs_fsync_range(iocb->ki_filp,
				iocb->ki_pos - count, iocb->ki_pos - 1,
				(iocb->ki_flags & IOCB_SYNC) ? 0 : 1);
		if (ret)
			return ret;
	}

	return count;
}
----
generic_write_sync(): 在文件具备同步刷写属性的情况下，保证数据从缓存刷写到磁盘后再返回。

=== 参考
